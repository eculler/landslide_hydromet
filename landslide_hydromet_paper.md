---
title: A multi-sensor evaluation of precipitation uncertainty for landslide-triggering storm events
author: 
  - Elsa Culler
  - Andrew Badger
  - Toby Minear
  - Kristy Tiampo
  - Ben Livneh
abstract: "Extreme precipitation can have profound consequences for communities, resulting in flooding and rainfall-triggered landslides that cause casualties and extensive damage each year. A key challenge to understanding and predicting these natural hazards comes from uncertainties in the depth and intensity of precipitation preceding the landslide event. Practitioners and researchers must select among a wide range of precipitation products, often with little guidance. Here we investigate the degree of precipitation uncertainty across multiple precipitation products for a large set of landslide-triggering storm events and assess the impact of uncertainties on predicted landslide probability using published intensity-duration thresholds. The average intensity, peak intensity, duration and NOAA Atlas return periods are compared ahead of 257 reported landslide e across the continental US and Canada. Precipitation data are taken from four products that cover disparate measurement methods: near real-time and post-processed satellite (Global Precipitation Mission IMERG Early and Final calibrated precipitation), radar (Multi-Radar Multi-Sensor gauge bias-corrected precipitation), and gauge-based (North American Land Data Assimilation System v. 2 Forcing precipitation). These products also cover a range of spatial and temporal resolutions as well as spatial extent and near real-time or longer latency of data availability. Landslide-triggering precipitation was found to vary extensively on the basis of the measurement source with the depth of individual storm events diverging by as much as 247 mm with an average range of 38 mm. Peak intensity measurements, which are typically influential in triggering landslides, were also highly variable with an average range of 8.8 mm/hr and at times as much as 72 mm/hr. The two products using more ground-based observations (MRMS and NLDAS2) tended to perform better at identifying landslides using the published intensity and duration storm thresholds, but all products exhibited hit-ratios of greater than 0.68.  While not all storms predicted landslides successfully, a greater proportion of predicted landslides were seen when sub-setting the data to include only verified landslide locations. Overall, we recommend practitioners consider low-latency products like MRMS for investigating landslides, given their near-realtime data availability and good performance in detecting landslides, although practitioners would be well-served considering more than one product as a way to confirm intense storm signals and minimize the influence of noise."

output:
  docx:
    output: output/landslide_hydromet_paper.docx
    filter: 
      - pandoc-crossref
    citeproc: true
    reference-doc: templates/HydrologicalProcessesResearchArticleTemplate.docx

bibliography: hydromet.bib
---

# Introduction

Precipitation measurements are intrinsically linked with the study and mitigation of rainfall-triggered landslides because these natural disasters occur in places that are otherwise susceptible to mass movements as a result of some combination of excess runoff and saturation of the soil column [@highlandLandslideHandbookGuide2008]. In spite of the destructive nature of landslides, which cause tens of thousands of deaths each year [@froudeGlobalFatalLandslide2018]these events remain challenging to forecast in part due to uncertainty in precipitation leading up to the event [@kirschbaumSatelliteBasedAssessmentRainfallTriggered2018]. There are many other sources of uncertainty that contribute to poor landslide predictions such as unknown soil properties, vegetation, and anthropogenic modifications to surface and subsurface soil structure. However, perhaps the largest source of uncertainty in landslide probability estimates is hydrologic uncertainty, defined here as uncertainty in the depth and intensity of liquid precipitation leading up to the event [@chowdhuryUncertaintiesRainfallinducedLandslide2002]. A confounding factor is the wide array of precipitation datasets ranging from in situ observations, ground-based radar and satellite retrievals. The goal of this analysis is to investigate the role of precipitation uncertainty preceding known historical landslide events, and to assess the implications of that uncertainty for evaluating landslide hazards. Greater understanding areas of relative agreement and divergence across products may provide guidance to practitioners and researchers choosing precipitation products for studying landslides.

The precipitation products chosen for this inter-comparison represent three broad categories of primary measurement techniques: precipitation gauges, ground-based radar, and microwave satellite. Precipitation gauges operate by periodically measuring how much precipitation has landed in the gauge. Their main strength is that they directly measure the amount of collected water, but nonetheless they suffer from issues of persistant bias driven by by under-catch from wind [@pollockQuantifyingMitigatingWindInduced2018] instrument malfunctions  [@duchonUsingHighSpeedPhotography2014, @duchonUndercatchTippingbucketGauges2010], placement of gauges too close to other structures [@voseImprovedHistoricalTemperature2014], ), and sparse sensor density relative to surrounding areas limiting representativeness  [@kiddHowMuchEarth2017]. Ground-based radar can detect precipitation based on propagation and backscatter of radar, and therefore can detect subtle variations in precipitation potentially hundreds of kilometers away. However, radar is an indirect measurement of precipitation that requires conversion of the radar signal to precipitation volume and is further limited by beam blockage and interference from buildings or even insects in the radar's path [@fornasieroImpactCombinedBeam; @bousquetObservationsImpactsUpstream2003; @nikahdReviewUncertaintySources2016]. Most ground-based radars use multiple bands of radar and multiple polarities in order to compute the raindrop shape and size distributions used in the processing, which offers an advantage over other indirect techniques such as those incorporated into satellite-based measurements [@chandrasekarPotentialRoleDualPolarization2008]. Satellite techniques vary in terms of which sensors they use to detect precipitation, including active and passive microwave, infrared, radar, or any combination, and depending on the sensor type these can be deployed in either geostationary or low Earth orbits that cover particular regions at particular intervals [@huffmanIntegratedMultisatelliteRetrievals2020a]. The key advantage of satellite-based precipitation measurements is that unlike ground-based  in situ or radar sensors they can deliver frequent, spatially continuous, precipitation measurements, although typically multiple satellites [@tapiadorGlobalPrecipitationMeasurement2012] with a variety of sensors and orbits [@ashouriPERSIANNCDRDailyPrecipitation2015] are required to provide global coverage. Many of the challenges associated with satellite-based precipitation measurement are related to sensor calibration and bias-correction relative to ground-based measurements [@ebertMethodsVerifyingSatellite2007], as well as the development of algorithms for merging measurements from diverse sources [@huffmanTRMMMultisatellitePrecipitation2007; @skofronick-jacksonGlobalPrecipitationMeasurement2017]. Estimating drop size distributions is also a challenge, though it can be addressed through the use of either ground- or satellite-based radar.

Precipitation measurements have been compared on the basis of a number of metrics in prior studies ranging from annual and monthly totals [@adlerIntercomparisonGlobalPrecipitation2001] to the largest number of consecutive dry days [@manzanasPrecipitationVariabilityTrends2014]. Less attention has been paid to metrics most directly useful for predicting and understanding rainfall-triggered landslides. While some landslides are triggered by short, intense precipitation events, others are triggered by saturation of the soil column that can develop over a longer period of time [@cannonWildfirerelatedDebrisFlow2005]. In both cases the triggering event occurs over the course of hours or days rather than months or years, and for some landslides the critical time period may be less than an hour of intense rainfall. As a result, this study focuses on precipitation products with hourly or finer temporal resolution to facilitate an evaluation of individual storm events.

Existing precipitation intercomparisons often focus on specific applications, for example for evaluating grid-based products over complex terrain, or relevant for portraying hydrologic phenomena [@hennAssessmentDifferencesGridded2018, @lundquistHighElevationPrecipitationPatterns2015, @ahmadalipourAnalyzingUncertaintyEnsemblebased2017] for climate model downscaling efforts  [@gutmannIntercomparisonStatisticalDownscaling2014; @wangProjectedChangesPrecipitation2020] or for merging multiple sensors together [@beckMSWEP3hourly252017]. A general review of 30 gauge-based, satellite-based, and reanalysis global precipitation products by @sunReviewGlobalPrecipitation2018 compared systematic and random errors for daily and annual precipitation, reporting large disagreements even within the same class of product, i.e. a deviation of 300 mm in annual precipitation among satellite products. They conclude that the placement and density of gauges accounts for many of the errors in gauge-based or gauge-corrected products, further suggesting that cross validation across multiple datasets is crucial to account for errors. @adlerVersion2GlobalPrecipitation2003 similarly analyzed 31 gauge-based, satellite-based, model-based, and climatological datasets in terms of monthly precipitation, finding that ‘quasi-standard’ products, e.g. those like the Global Precipitation Measurement mission (GPM) [@houGlobalPrecipitationMeasurement2014] that have undergone substantial testing, perform better. Additionally, they report that products incorporating both in situ and satellite information (e.g. the Global Precipitation Climatology Project [GPCP] ) perform better than products based on a single data source.

Fewer studies comparing extreme precipitation exist, with many focusing on climate model simulations [@sunyerIntercomparisonStatisticalDownscaling2015; @tryhornComparisonTechniquesDownscaling2011]  and trends [@janssenObservationalModelbasedTrends2014; @baoFutureIncreasesExtreme2017] while others focusing on observations and satellites [@pendergrassUnevenNatureDaily2018; @aghakouchakEvaluationSatelliteretrievedExtreme2011; @lockhoffEvaluationSatelliteRetrievedExtreme2014]. @aghakouchakEvaluationSatelliteretrievedExtreme2011 compared extreme precipitation across four satellite platforms finding tradeoffs across products in terms of correct identification of precipitation above a threshold and measurements of the volume of identified extreme storms. Though they found that some datasets performed better than others in certain contexts, they ultimately concluded that no single precipitation product was ideal for detecting extremes because all of them failed to detect a significant amount of precipitation. @lockhoffEvaluationSatelliteRetrievedExtreme2014 found that satellite retrieved extreme precipitation values matched station-based precipitation when using fuzzy metrics to evaluate agreement at larger spatiotemporal scales of ~330 km and 5 days. @pendergrassUnevenNatureDaily2018 showed that precipitation was less uneven in coarser versus finer-resolution satellite precipitation datasets, suggesting that coarser precipitation products may be unable to capture extreme precipitation to the same extent as higher resolution datasets. Other studies primarily evaluated extreme precipitation indicators like 90th percentile precipitation, extreme one-day precipitation and maximum number of consecutive wet days [@amitaiMultiplatformComparisonsRain2012; @manzanasPrecipitationVariabilityTrends2014]. These measures are meant to capture large storms that happen on at least an annual basis rather than storms that rise to the level of a natural disaster [@sunReviewGlobalPrecipitation2018; @manzanasPrecipitationVariabilityTrends2014].

 In a comparison of satellite and gauge precipitation data specific to landslide sites in Italy, @rossiComparisonSatelliteRainfall2017 found that data from Tropical Rainfall Measuring Mission (TRMM) satellite products [@kummerowTropicalRainfallMeasuring1998] tend to underestimate gauge data, particularly in mountainous areas where landslides are most likely to occur. They conclude, that the satellite data are still useful for forecasting landslides as long as they are scaled appropriately to correct for local bias.

The intensity-duration threshold is a type of two-parameter statistical model used for landslide early warning systems, where rainstorms above the threshold curve are predicted to cause landslides [@scheevelPrecipitationThresholdsLandslide2017]. The curves are typically based on a power law (e.g. $I = a D^{-b}) and are valid in a particular region or climate and for a range of durations based on the training data [@guzzettiRainfallIntensityDuration2008]. This study will use several power-law intensity-duration thresholds reviewed by @guzzettiRainfallIntensityDuration2008 as a straightforward way to compare precipitation measurements from different sources in the context of concerns specific to landslide hazard estimation.

Given the wide-ranging issues associated with precipitation estimation cited above, this study presents a multi-product, multi-site analysis focused on landslide-triggering storms. This address an existing gap in evaluating extreme precipitation through the lens of natural hazards, while conducting inter-product analyses into storm characteristics of broader relevance. This work furthers the analysis by @rossiComparisonSatelliteRainfall2017 who compared gauge and satellite precipitation for the purposes of landslide modeling by additionally including a ground-based radar product and by singling out observations preceding specific landslide events.

In @sec:methods, we will present the selection of landslide sites and precipitation products, followed by procedures for splitting precipitation into storms and the metrics used in the comparison. @Sec:results begins with an exposition of cumulative observed precipitation over the 30-days preceding the landslide for five characteristic example sites. Next, we compare each product using storm characteristics of total depth, duration, total intensity, peak intensity, and return period. We further test whether peak intensity might be accounting for low return period storms causing landslides by comparing the two quantities. Finally, we use established intensity-duration thresholds to test which products have the best separation between landslides and other rainfall, comparing the hit ratio and the false alarm ratio for each product and threshold.

# Methods {#sec:methods}

The overall goals of the methods are to evaluate precipitation characteristics at known landslide sites by first examining the features of triggering storms and then subsequently comparing precipitation estimates in the context of published intensity-duration models of landslides occurence. Rainfall-triggered landslide sites were chosen from the NASA Global Landslide Catalog with a subset of landslide locations verified with ancillary satellite imagery (see @sec:site_selection). For each landslide location, precipitation was obtained from four different products (see @sec:precip_data) and then the precipitation time series were split into individual storms events, and key characteristics of total depth, duration, intensity, peak intensity, and return period were calculated relative to a reference dataset (@sec:compute_storms). Finally, the storm events were plotted relative to landslide intensity-duration curves, with hit-ratios and false-alarm-ratios computed for each model-product combination (@sec:compute_idt_scores). 

## Study domain and landslide site selection {#sec:site_selection}

Landslides were selected from the NASA Global Landslide Catalog (GLC) [@kirschbaumGlobalLandslideCatalog2010]. The GLC was chosen for this study, since it provides a large sample of landslide locations useful for evaluating heavy rainfall events.  The GLC shares strengths and weaknesses with the few other regional and global databases available. Though the GLC covers a broad spatial and temporal domain, it suffers problems with precision and
completeness. The source of these data are second-hand observations made by
organizations like the news media, governmental organizations like departments of transportation, and some available scientific reports. In all cases,
landslides that are causing problems for people are reported more frequently, resulting in a substantial spatial bias towards populated areas. The landslide reports suffer relatively high location error (as much as 50 km) depending on how specific the source article is about the location [@kirschbaumGlobalLandslideCatalog2010], and this was evident in that it was only possible to definitively locate one thirdy of the landslides in this study on satellite imagery. Despite these limitations, it was deemed fit for purpose for this study which is not to study a selection of landslides with a representative spatial distribution but rather to compare precipitation products in the vicinity of hydrologically-triggered landslides where heavy rainfall events are likely to be present. Since work on this study began, a complilation of U.S. landslides has been released by the USGS [@mirusLandslidesUSAOccurrence2020] which would also be a suitable source of landslide locations with perhaps greater location precision for future work along the same lines. The GLC was able to provide a substantialnumber of landslide locations for this study, while ensuring quality control and data availability. The following selection criteria were used to qualify landslide sites:

* Landslide events were reported as rainfall-driven, with a GLC trigger category rain, downpour, continuous rain, or flooding (snow-related triggers were not included even though that is a hydrologic process since precipitation is not necessarily and important factor in those landslides)
* Landslide events took place in the continental United States (CONUS) or Canada below $60^o$N  and after May 2015 ensuring data availability across each of the selected precipitation products; and
* The landslide location accuracy was estimated to be $10$ km or less according to the GLC. The value of 10km was chosen since it is approximately equal to the spatial resolution of two of the precipitation products.

 In total, 228 landslides were selected. Of those landslides, 80 were also verified by a trained technician searching a visible scarp in satellite images of the terrain near the specified landslide location; the location specified by the NASA GLC was used for the remaining landslides. Of the unverified landslides, 31 were marked in the GLC as exact locations, 51 as 1 km, 52 as 5 km and 14 as 10 km accuracy. @Fig:site_map shows that many of the sites are located near the Pacific coast, likely due to the complex topography associated with landslides, as well as the population reporting bias of the GLC. The verified landslides seem to be spatially distriubuted fairly evenly relative to the distribution of the full selection of landslides.


![Map of all landslide sites considered in this analysis (n=228), colored by whether the location was approximate (n=148) or verified using aerial satellite imagery to identify a visible scarp (n=80); Source of landslide locations was the GLC [@kirschbaumGlobalLandslideCatalog2010], source of the DEM data used for the basemap [@governmentofcanadaNorthAmericaElevation2007].](landslide_hydromet_paper.assets/site_map.png){#fig:site_map}

## Precipitation data sources {#sec:precip_data}

The gridded precipitation datasets selected for this study were chosen to be reflective of three common measurement methods: gauges, ground-based radar, and satellite. In addition, we focused on products that were both freely available, having undergone extensive verification, and with coverage over at least the CONUS. An important additional criteria was that products be available at an hourly temporal resolution or finer in order to compute the characteristics of individual storm events. We further sought to include products with multiple latencies where available. The above criteria resulted in the precipitation products and features described in @tbl:products and summarized in the following paragraphs.

### North American Land Data Assimilation System version 2 (NLDAS-2) meteorological dataset

The NLDAS-2 meteorological dataset is a combination of daily gauge-based National Center for Environmental Prediction (NCEP) Climate Prediction Center (CPC) precipitation with orographic corrections and hourly NCEP Doppler radar-based precipitation [@xiaContinentalscaleWaterEnergy2012].  The gauge-based estimates are are disaggregated to hourly using the radar-based estimates, resulting in a near real-time hourly gridded product at $0.125^o$ (~$12$ km) resolution across North America going back to 1979 with a latency of approximately 4 days. Though it has low horizontal resolution relative to the other precipitation products used here, NLDAS-2 meteorological is a widely used gauge-based product that has been extensively validated over the 20 years.

### Multi-Radar Multi-Sensor (MRMS) Quantitative Precipitation Estimate

MRMS precipitation estimates are primarily based on a centralized radar mosaic with 2 minute resolution over the US and Canada. This study uses an hourly version that also integrates data from numerical weather prediction, satellites, gauges, lightning sensors, and precipitation models [@zhangMultiRadarMultiSensorMRMS2015]. While both NLDAS-2 and MRMS estimates contain common information from gauges and radar, the NLDAS-2 product is primarily a gauge-based estimate while MRMS focuses on radar inputs. MRMS is the precipitation product with the shortest period of record among the products selected for this study, and so there are relatively few years of data for validation. However, it has by far the highest resolution at $.01^o$ (~1.1 km) and represents the state of the art in terms of leveraging computing resources to take advantage of a multitude of overlapping radar and other types of sensors.

### Global Precipitation Mission (GPM) Integrated Multi-satellitE Retrievals for  Global  (IMERG) precipitation measurement

GPM IMERG precipitation estimates are a combination of multiple satellite measurements, including the GPM Core Observatory Microwave Imager which is considered the standard for other included satellites. In addition to active and passive microwave sensors, IMERG estimates include Infrared sensors, satellite-based radar, and precipitation gauge adjustments. The gauges are used for monthly bias correction [@huffmanIntegratedMultisatelliteRetrievals2020a]. There are 3 IMERG products, Early, Late, and Final, of which we use the Early (~4 hour latency) and the Final (~3.5 month latency) in this study. The IMERG-Early product is available much more quickly than the IMERG-Final, but as a result some of the satellite retrievals are not included because they have not yet arrived, and it cannot take advantance of some processing steps or monthly gauge correction [@oEvaluationGPMIMERG2017]. IMERG-Final is recommended for research applications as being the most accurate, but would not be useful for predicting landslides in a timely fashion [@huffmanIntegratedMultisatelliteRetrievals2020c]. Since IMERG products use the GPM active and passive microwave data as a standard with little-to-no information from gauges, they are fundamentally different from many other precipitation products available. IMERG-Early also has extremely small latency, making it the most suitable among the products explored here for operational landslide modeling in the context of near real-time data availability. 

| Precipitation product                                        | Description                                                  | Spatial Resolution | Temporal resolution | Typical Latency |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------ | ------------------- | --------------- |
| Integrated Multi-satellitE Retrievals for  Global precipitation measurement early run (IMERG-Early)[@houGlobalPrecipitationMeasurement2014] | Global network of satellites unified by measurements from a single reference radar/radiometer satellite. | $.1^o$ (~10 km)    | 30 minutes          | 4 hours         |
| Integrated Multi-satellitE Retrievals for  Global precipitation measurement (IMERG-Final)[@houGlobalPrecipitationMeasurement2014] | In addition to the satellite data included in the IMERG early run, the final run includes late-arriving microwave overpasses, monthly gauge-based adjustments, and an algorithm that interpolates forward as well as backward in time. | $.1^o$ (~10 km)    | 30 minutes          | 3.5 months      |
| Multi-Radar Multi-Sensor (MRMS) [@zhangMultiRadarMultiSensorMRMS2015] | Integrates data from radars, satellites, precipitation gages, and other sensors to provide real-time decision support | $.01^o$ (~1.1 km)  | 2 minutes           | < 5 minutes     |
| North American Land Data Assimilation System version 2 (NLDAS-2) meteorological  [@xiaContinentalscaleWaterEnergy2012] | Disaggregation of Climate Prediction Center  daily precipitation using bias-corrected radar | $.125^o$ (~ 12 km) | 1 hour              | 4 days          |

: 3 The four precipitation products included in the comparison, representing gauge-, radar-, and satellite-based measurements {#tbl:products}

## Precipitation inter-comparison and computation of storm characteristics {#sec:compute_storms}

For each of the above precipitation products, data were extracted for the nearest grid location for the period between May 2015 (the earliest date MRMS data are available) and May 2020 (the latest release of IMERG-Final data). A minimum threshold of 1 mm was applied to the precipitation data to reduce noise. The data were then split into storm events, where a gap of at least 24 hours was considered to mark the end of one storm and the beginning of the next. 

For each storm, the characteristics of total depth, duration, intensity, and peak intensity were computed and compared. The peak intensity for a storm was the intensity of the single maximum precipitation measurement of the storm. Depth and frequency were chosen since they reflect the most common metrics used in extreme hydrologic events in general [@englandjr.GuidelinesDeterminingFlood2019]. Intensity and duration were included because they are parameters commonly used to forecast rainfall-triggered landslides [@kirschbaumAdvancesLandslideNowcasting2012]. Some studies have suggested that for certain landslides high peak intensity can contribute significantly to triggering a landslide independent of the overall storm depth, duration or intensity [@yuLandslidesRainfallCharacteristics2006; @corominasLandslideRainfallTriggers2002].  This idea is supported for example by observations that landslides are commonly initialized within hours of the peak intensity [@premchittLandslidesCausedRapid1986]. The precipitation rank and z-score among the four products for each landslide event were also computed for the day of the landslide as well as for the full precipitation record. Rank was chosen as in indicator of the relative magnitude of each product relative to the others, and the z-score is an indicator of the variability of each product relative to the others.

To facilitate comparison of storm characteristics within a single over-arching framework, the return period of the landslide-triggering storms was also computed using the NOAA precipitation atlas frequency estimations [@NOAAAtlasPrecipitation]. The NOAA atlas provides return periods for discrete precipitation durations, namely 1, 2, 3, 6, 12, 24, 48, 72, 96, and 168 hours. In order to define a consistent return period for each storm, we used the maximum precipitation value for each applicable NOAA atlas duration rather than attempting to round the storm duration to one of the NOAA atlas durations which might have artificially lowered the return periods. For example, for the 3-hour duration, cumulative 3-hour precipitation totals were calculated for each time step of the storm, and the maximum value chosen. The return period for this maximum value was then looked up in the NOAA atlas. We then selected the maximum return period from among the 10 possible durations noted above for each landslide. This procedure ensured that we used the maximum applicable return period available from the NOAA atlas that occurred during each landslide-triggering storm.

## Performance of intensity-duration thresholds using different precipitation products  {#sec:compute_idt_scores}

Intensity-Duration thresholds represent simple models of landslide occurence whereby a threshold is defined as a power law of the storm duration ($I = a D^{-b}$, where I is intensity and D is duration), where either raw or normalized intensities above the threshold predict the occurance of a landslide [@segoniLandslidesTriggeredRainfall2014].  Thresholds have been calculated under different climates and over multiple scales, including globally  [@scheevelPrecipitationThresholdsLandslide2017, @caineRainfallIntensityDuration1980, @kirschbaumAdvancesLandslideNowcasting2012]. Three thresholds for this study [@caineRainfallIntensityDuration1980, @cannonWildfirerelatedDebrisFlow2005, @guzzettiRainfallThresholdsInitiation2007]  were obtained from a review by @guzzettiRainfallIntensityDuration2008. Thresholds were used on applicable subsets of the data based on climate or other conditions. For example, a threshold for “mild, marine west coast climates” was only used on data west of longitude 155W. For each threshold-product combination, we computed a hit ratio (correctly predicted landslides over the total number of landslides) and a false alarm ratio (incorrectly predicted landslides over the total number of non-landslides)

# Results {#sec:results}

## Precipitation pre-landslide time series

@Fig:cumulative shows the cumulative precipitation in the 30-days before a landslide at 5 example sites.  The selected sites showcase a variety of ways in which the precipitation from multiple products can differ. For example, while the preciptiation in panel (a) matches closely for all products, in panel (d) there is a wide spread of over 100 mm of precipitation that happens suddenly during the landslide-triggering event. The preciptiation in panel (b) also demonstrates a factor of 6 spread of precipitation values but appears to be more strongly correlated than other sites. In panel (c) the IMERG-Early product separates substatially but ultimately the 30-day depth is nearly identical for all products. Panel (e) shows a likely landslide location error since none of the products register any precipitation at all. We note that the differences in precipitation depths accumulated over these 30-day periods are of the same order of magnitude as the *annual* error in depth reported for products of the same category by @sunReviewGlobalPrecipitation2018. This could be because using products from different categories introduces much more variability, or that the large landslide-triggering storms have a greater potential for error by virtue of containing more depth overall than other storms). 

![**Exposition into the types of precipitation differences leading up to landslide events:** Cumulative precipitation measurements at select landslide sites for the 30 days before the event. The precipitation is variable across the different products, and the selected sites each demonstrate diverse types of variability. Panel (a) shows a site where there weresimilar measurements among all products throughout the 30 days. In panel (b), all products are well correlated, but the accumulated depths greatly differ. In panel (c) shows the IMERG-Early product reports nearly 50mm less cumulative precipitation leading into the landslide-triggering storm, but then makes up the difference by detecting much more precipitation immediately before the landslide. In panel (d) there is a wide spread of approximately half the maximum total amount of precipitation. Finally, in panel (e) no landslide-triggering precipitation was detected by any product, suggesting a location error in the landslide record. ](landslide_hydromet_paper.assets/example_landslide_precipitation.png){#fig:cumulative}

The relative magnitude of the different precipitation products on the day of the landslide is shown in @Fig:bias_variability in terms of the rank among the four products for each day, and z-score among all non-zero data for a particular product. Both day-of-landslide precipitation and all other non-zero days in the study period are shown for comparison. The IMERG products appear to have identical ranks, which exceeds MRMS and is less than NLDAS-2 measurements. IMERG-Early has the highest z-scores among day-of-landslide preciptiation, suggesting that the further interpolation in the IMERG-Final product reduces these outliers relative to IMERG-Early, although the median and third quartile values for IMERG-Final are the larger overall. There are larger z-scores in the entire record than the most extreme day-of-landslide precipitation, but for all products the bulk of the day-of-landslide precipitation is larger than most of the non-landslide-triggering precipitation.

![**Relative magnitude of precipitation products on the day of the landslide**: Rank among all products for the day, and z-score of precipitation as measured by each product for each of 228 events. Metrics are divided by the day of the landslide and the rest of the daysin the](landslide_hydromet_paper.assets/summary_statistic.png){#fig:bias_variability}

@Fig:scatter shows the characteristics of the landslide-triggering storms plotted against the ensemble mean of all the products by landslide event. Included are values for all the landslide sites and for the verified locations alone. The IMERG products generally report higher peak hourly intensities, which is likely at least partially due to the shorter 30-minute time step. However, the higher peak intensities are more clearly reflected in longer return periods, which are based on hourly durations or longer for comparison with the NOAA Atlas. MRMS and NLDAS-2 seem to have even lower return periods among the verified locations, suggesting that these products have difficulty detecting high return period precipitation consistently.

In general there appears to be good agreement among products on the depth and duration of storms, with the exception of outliers below 10mm of total depth—which is a fairly modest storm depth. Among the verified locations, there are fewer low depth or duration values that are either outliers or near to the mean, suggesting that low measurements may reflect limitations in the GLC location accuracy for sites with only approximate locations.



![**Storm characteristics vs. the ensemble mean:** Depth, duration, intensity, peak intensity, and return period for each of the landslide-triggering storms as measured by four precipitation products. Least-squares regression lines with $95\%$ confidence intervals are also shown. Top panels show all 228 sites while the bottom panel only shows the 80 verified locations.](landslide_hydromet_paper.assets/scatter_ensemble_mean.png){#fig:scatter}

@Fig:intensity_duration shows the precipitation on intensity/duration axes with three intensity-duration thresholds plotted over them, and @tbl:threat summarizes the performance of each threshold. The choice of threshold does not appear to make a large difference in this context, since the models are very similar when compared to the variation in precipitation data across sites and among products. These models tend to perform better using MRMS or NLDAS-2 data than using either IMERG product, with hit ratios of 0.88 and 0.76 rather than 0.70 and 0.68 among the verified landslide locations. All products perform better when using only the verified landslide sites.

The precipitation products are examined in the context of landslide triggering threholds in Fig. 6, which shows the precipitation on intensity vs. duration axes with three intensity-duration thresholds plotted over them, with the performance summarized in Table 2. Interestingly, the choice of intensity-duration threshold does not appear to make a large difference in this context, since the threshold curves are very similar when compared to the variation in precipitation data across sites and among products. The MRMS or NLDAS-2 products tend to perform better than either IMERG product, with hit ratios of 0.88 and 0.76 rather than 0.70 and 0.68 among the verified landslide locations, respectively. All products perform better when using only the verified landslide locations relative to the approximate locations.

There is a concentration of long-duration, low-intensity storms around 24 hours for all products that may an artifact of the storm identification algorithm. Since the landslides did not have times specified, the whole day of the landslide was always included unless there was no rain all the way until the end of the day. This could have resulted in lower total intensity values for storms that lasted only through the day of the landslide but tapered off towards the end of the day. Many of the storms that did trigger landslides but were not correctly identified by the intensity-duration threshold fall into this section of approximately 24-hour low-intensity storms. Improvements to storm delineation through a different algorithm or a higher minimum threshold might boost performance. The IMERG data in particular might benefit from such improvements.



![Each storm in the precipitation record and established global or climactic intensity-duration thresholds. Landslide-triggering storms are marked. It appears that these models generally perform better when using MRMS or NLDAS-2 data, since the IMERG products detect a larger number of low intensity values for landslide-triggering storms.](landslide_hydromet_paper.assets/intensity_duration.png){#fig:intensity_duration}



| Product         | Include  | **Hits** | **Misses** | **Hit ratio** | **False alarm ratio** |
| --------------- | -------- | -------- | ---------- | ------------- | --------------------- |
| GPM IMERG Early | All      | 114      | 62         | 0.648         | 0.269                 |
|                 | Verified | 44       | 21         | 0.677         | 0.298                 |
| GPM IMERG-Final | All      | 117      | 60         | 0.661         | 0.307                 |
|                 | Verified | 45       | 19         | 0.703         | 0.339                 |
| NLDAS-2         | All      | 114      | 40         | 0.740         | 0.221                 |
|                 | Verified | 45       | 14         | 0.763         | 0.223                 |
| MRMS            | All      | 130      | 26         | 0.833         | 0.243                 |
|                 | Verified | 52       | 7          | 0.881         | 0.264                 |

Table: Threat score, hit ratio, and false alarm ratio for each product and the @guzzettiRainfallThresholdsInitiation2007 intensity-duration threshold {#tbl:threat_guzzetti}

| Product         | Include  | **Hits** | **Misses** | **Hit ratio** | **False alarm ratio** |
| --------------- | -------- | -------- | ---------- | ------------- | --------------------- |
| GPM IMERG Early | All      | 69       | 77         | 0.473         | 0.107                 |
|                 | Verified | 31       | 28         | 0.525         | 0.126                 |
| GPM IMERG-Final | All      | 76       | 69         | 0.524         | 0.135                 |
|                 | Verified | 33       | 23         | 0.589         | 0.160                 |
| NLDAS-2         | All      | 89       | 42         | 0.679         | 0.184                 |
|                 | Verified | 36       | 19         | 0.655         | 0.177                 |
| MRMS            | All      | 52       | 41         | 0.559         | 0.208                 |
|                 | Verified | 26       | 15         | 0.634         | 0.210                 |

Table: Threat score, hit ratio, and false alarm ratio for each product and the @cannonStormRainfallConditions2008 intensity-duration threshold for burned areas. Since most of these sites were not burned, this threshold tends to capture more false alarms {#tbl:threat_cannon}

| Product         | Include  | **Hits** | **Misses** | **Hit ratio** | **False alarm ratio** |
| --------------- | -------- | -------- | ---------- | ------------- | --------------------- |
| GPM IMERG Early | All      | 80       | 66         | 0.548         | 0.161                 |
|                 | Verified | 35       | 24         | 0.593         | 0.187                 |
| GPM IMERG-Final | All      | 89       | 56         | 0.614         | 0.200                 |
|                 | Verified | 54       | 39         | 0.581         | 0.251                 |
| NLDAS-2         | All      | 97       | 34         | 0.740         | 0.236                 |
|                 | Verified | 45       | 14         | 0.763         | 0.223                 |
| MRMS            | All      | 54       | 39         | 0.581         | 0.251                 |
|                 | Verified | 42       | 13         | 0.764         | 0.232                 |

Table: Threat score, hit ratio, and false alarm ratio for each product and the @clarizia1996sui intensity-duration threshold. {#tbl:threat_clarizia}

# Discussion

Among the precipitation products chosen for this study, both IMERG products identify both higher peak intensities and larger return periods relative to the other products. Interestingly, they also detect more anomalously low precipitation values. Low-intensity precipitation in all products was associated with long duration storm events (see @fig:intensity_duration), which may occur because of noisy low-precipitation slightly above the 1 mm threshold extending the computed duration of the storm and reducing its overall intensity. As a result, it appears that while every product could benefit from an enhanced storm delineation process that prevents the intensity from being diluted, the IMERG products were particularly vulnerable to the identification of long-duration low-intensity storms as a result of the method used in this study to separate storms. Those long-duration low-intensity storms tended to bring the hit ratio down for the intensity-duration thresholds. It is possible that many of the long-duration low-intensity precipitation events could be effectively filtered out by using a different storm delineation algorithm. Since the IMERG products were both able to identify higher intensity precipitation than the other products, it is possible that they would in fact perform better for identifying landslides if the low-intensity storm problem were mitigated.

The precipitation products performed reasonably well at identifying landslides using the published intensity-duration thresholds particularly considering that these thresholds were developed on training data spanning large regions and different sources of precipitation data than those used in this study. However, they fared more poorly at excluding false alarms, most likely because there are factors beyond intensity and duration that can influence landslide occurrence such as topography, soil type, recent wildfire or disturbance or land development. Some of the high-intensity precipitation that did not trigger any recorded landslides may be more reflective adjacent areas that are not as susceptible to landslides. Conversely a landslide at a highly susceptible location, such as an area with high slopes that had recently been burned by wildfire could be triggered by less intense rain, potentially endgin up as a miss on an intensity-duration curve. Even the 1.1 km resolution of the MRMS data could contain substantial variation in landslide susceptibility within an individual grid cell. The poorest performing products were the IMERG products despite their detecting more high-intensity events but because they also detected many low intensity events, causing the intensity-duration threshold to miss landslides.

MRMS and NLDAS-2 are relatively low latency products. In the case of IMERG-Early the short latency seemed to come at a cost of an exaggeration of the weaknesses and strengths of IMERG in identifying landslides. In particular, IMERG-Early had the greatest prevalence of low storm intensities, and so it ultimately performed the worst at landslide identification. Without changes to the precipitation processing, the low latency does indeed appear to be a liability in this case.

Precipitation measurements at verified landslide sites tended to be of higher magnitude than those at other sites with approximate locations. This suggests that some of the approximate landslide locations were too far away from the true landslide location for the precipitation measurements to be representative. The intensity-duration thresholds similarly performed better at verified locations across all precipitation products.

# Conclusion

The precipitation products chosen for this study represent diverse measurement techniques that often reported large differences in precipitation leading up to the landslide events evaluated here. As a result, the precipitation products differed in their overall performance in predicting landslides on the basis of published intensity-duration thresholds. A particular challenge was the presence of low-intensity, long-duration storms preceding landslide events. This challenge could potentially be addressed by better filtering and aggregating the data into more pronounced storm events. Overall, the choice of intensity-duration threshold was not as consequential as the choice of precipitation product in identifying landslides. Performance from products that rely on ground-based sensors showed a more easily identifiable landslide signal despite generally recording lower peak intensities and return periods. Though it was hypothesized that peak intensity would be an important predictive factor, the results suggest instead that a lack of noise on the low end may be more important for accurate landslide identification.

A major limitation to studies of landslide-triggering precipitation is the lack of verifiable exact landslide locations and times. This limitation was reflected in the results for verified landslide locations as compared to approximate locations, which strongly imply that some of the approximate locations were incorrect to such an extent that the precipitation measurements were inaccurate. This problem can be addressed by more extensive manual searches such as the one used in this study that identified the 80 verified landslide locations, or perhaps in the future by machine learning methods.

Using the methods of this study, those practitioners attempting to use intensity-duration thresholds as operation landslide models would do well to select a product like MRMS that has extremely low latency and performs well at identifying landslides. None of the products was particularly good at filtering out false alarms of landslides. A model that takes into account landslide susceptibility has the potential to reduce false alarms. Therefore, an additional recommendation would be for practitioners to consider more than one precipitation product, i.e. multiple precipitation estimates simultaneously, as a way to quantify stronger precipitation signals and to minimize the influence of noise.



# Bibliography