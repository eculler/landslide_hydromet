---
title: A multi-sensor evaluation of precipitation uncertainty for landslide-triggering storm events
abstract: "Extreme precipitation can have profound consequences for communities, resulting in natural hazards such as flooding and rainfall-triggered landslides that cause casualties and extensive property damage each year. A key challenge to understanding and predicting rainfall-triggered landslides comes from uncertainties in the depth and intensity of precipitation preceding the event. Practitioners and researchers must select among a wide range of precipitation products, often with little guidance. Here we evaluate the degree of precipitation uncertainty across multiple precipitation products for a large set of landslide-triggering storm events and investigate the impact of these uncertainties on predicted landslide probability using published intensity-duration thresholds. The average intensity, peak intensity, duration, and NOAA Atlas return periods are compared ahead of 257 reported landslides across the continental US and Canada. Precipitation data are taken from four products that cover disparate measurement methods: near real-time and post-processed satellite (Integrated Multi-satellitE Retrievals for Global Precipitation Mission), radar (Multi-Radar Multi-Sensor gauge bias-corrected precipitation), and gauge-based (North American Land Data Assimilation System v. 2 meteorological dataset). These products also cover a range of spatial and temporal resolutions as well as spatial extent and near real-time or longer latency of data availability. Landslide-triggering precipitation was found to vary extensively on the basis of the measurement source with the depth of individual storm events diverging by as much as 247 mm with an average range of 38 mm. Peak intensity measurements, which are typically influential in triggering landslides, were also highly variable with an average range of 8.8 mm/hr and at times as much as 72 mm/hr. The two products more reliant upon ground-based observations (MRMS and NLDAS-2) tended to perform better at identifying landslides using the published intensity and duration storm thresholds, but all products exhibited hit-ratios of greater than 0.68. While not all storms predicted landslides successfully, a greater proportion of predicted landslides were seen when sub-setting the data to include only manually-verified landslide locations. Overall, we recommend practitioners consider low-latency products like MRMS for investigating landslides, given their near-realtime data availability and good performance in detecting landslides, although practitioners would be well-served considering more than one product as a way to confirm intense storm signals and minimize the influence of noise and false alarms."

output:
  docx:
    output: output/landslide_hydromet_paper.docx
    filter: 
      - pandoc-crossref
      - pandoc-eqnos
    citeproc: true
    reference-doc: templates/HydrologicalProcessesResearchArticleTemplate.docx
    csl: apa.csl
    number-sections: true
bibliography: hydromet.bib
figPrefix: figure
tblPrefix: table

---

# Introduction

Precipitation measurements and their uncertainty are key to the study and mitigation of rainfall-triggered landslides because these natural disasters are triggered by excess runoff and saturation of the soil column [@highlandLandslideHandbookGuide2008]. In spite of the destructive nature of landslides, which cause tens of thousands of deaths each year [@froudeGlobalFatalLandslide2018] these events remain challenging to diagnose in part due to uncertainty in precipitation leading up to the event [@kirschbaumSatelliteBasedAssessmentRainfallTriggered2018]. There are many other sources of uncertainty that contribute to poor landslide predictions such as unknown soil properties, vegetation, and anthropogenic modifications to surface and subsurface soil structure. However, perhaps the largest source of uncertainty in landslide probability estimates is hydrologic uncertainty, defined here as uncertainty in the depth and intensity of liquid precipitation leading up to the event [@chowdhuryUncertaintiesRainfallinducedLandslide2002]. A confounding factor is the wide array of precipitation datasets ranging from in situ observations, ground-based radar and satellite retrievals.

The precipitation products chosen for this inter-comparison represent three broad categories of primary measurement techniques: precipitation gauges, ground-based radar, and microwave satellite. Precipitation gauges operate by periodically measuring the volume of precipitation collected at a gauge. Their main strength is that they directly measure the amount of collected water, but nonetheless they can suffer from issues of persistent bias driven by under-catch from wind [@pollockQuantifyingMitigatingWindInduced2018] instrument malfunctions  [@duchonUsingHighSpeedPhotography2014; @duchonUndercatchTippingbucketGauges2010], placement of gauges too close to other structures [@voseImprovedHistoricalTemperature2014], and limited spatial representativeness due to sparse sensor density [@kiddHowMuchEarth2017]. 

Ground-based radar detects precipitation using the propagation and backscatter of radar and can measure subtle variations in precipitation over regions of several hundreds of square kilometers [@zhangMultiRadarMultiSensorMRMS2015]. However, radar is an indirect measurement of precipitation that requires conversion of the radar signal to precipitation volume and is further limited by beam blockage and interference from buildings or even insects in the radar's path [@fornasieroImpactCombinedBeam2004; @bousquetObservationsImpactsUpstream2003; @nikahdReviewUncertaintySources2016]. Most ground-based radars use multiple bands of radar and multiple polarities to compute the raindrop shape and size distributions used in the processing, which offers an advantage over other indirect techniques such as those incorporated into satellite-based measurements [@chandrasekarPotentialRoleDualPolarization2008]. 

Satellite techniques vary in terms of which sensors they use to detect precipitation, including active and passive microwave, infrared, radar, or any combination, and depending on the sensor type these can be deployed in either geostationary or low Earth orbits that cover particular regions at particular intervals [@huffmanIntegratedMultisatelliteRetrievals2020]. The key advantage of satellite-based precipitation measurements is that unlike ground-based  in situ or radar sensors they can deliver frequent, spatially continuous, precipitation measurements, although typically multiple satellites [@tapiadorGlobalPrecipitationMeasurement2012] with a variety of sensors and orbits [@ashouriPERSIANNCDRDailyPrecipitation2015] are required to provide global coverage. For example, the satellite products used in this analysis are a combination of a fleet of geostationary satellites with a single low Earth orbit reference satellite [@kiddGlobalPrecipitationMeasurement2020]. Many of the challenges associated with satellite-based precipitation measurement are related to sensor calibration and bias-correction relative to ground-based measurements [@ebertMethodsVerifyingSatellite2007], as well as the development of algorithms for merging measurements from diverse sources [@huffmanTRMMMultisatellitePrecipitation2007; @skofronick-jacksonGlobalPrecipitationMeasurement2017]. Estimating drop size distributions is also a challenge, though it can be addressed through the use of either ground- or satellite-based radar.

Existing precipitation products have been compared and evaluated using a number of metrics in prior studies, for example for annual and monthly totals [@adlerIntercomparisonGlobalPrecipitation2001] or the frequency of wet or dry days [@manzanasPrecipitationVariabilityTrends2014]. Less attention has been paid to metrics most directly useful for predicting and understanding rainfall-triggered landslides. While some landslides are triggered by short, intense precipitation events, others are triggered by saturation of the soil column that can develop over a longer period of time [@cannonWildfirerelatedDebrisFlow2005]. In both cases the triggering event occurs over the course of hours or days rather than months or years, and for some landslides the critical time period may be less than an hour. For this reason, this study focuses exclusively on precipitation products with hourly or finer temporal resolution to facilitate an evaluation of individual storm events.

Published precipitation inter-comparisons typically focus on specific applications such as evaluating grid-based products over complex terrain, portraying hydrologic phenomena [@hennAssessmentDifferencesGridded2018, @lundquistHighElevationPrecipitationPatterns2015, @ahmadalipourAnalyzingUncertaintyEnsemblebased2017], climate model downscaling efforts  [@gutmannIntercomparisonStatisticalDownscaling2014; @wangProjectedChangesPrecipitation2020], or for merging multiple sensors together [@beckMSWEP3hourly252017]. A general review of 30 gauge-based, satellite-based, and reanalysis global precipitation products by @sunReviewGlobalPrecipitation2018 compared systematic and random errors for daily and annual precipitation, reporting large disagreements even within the same class of product, i.e. a deviation of 300 mm in annual precipitation over global land among satellite products. They conclude that the placement and density of gauges accounts for many of the errors in gauge-based or gauge-corrected products, further suggesting that cross validation across multiple datasets is crucial to account for errors. @adlerVersion2GlobalPrecipitation2003 similarly analyzed 31 gauge-based, satellite-based, model-based, and climatological datasets in terms of monthly precipitation, finding that ‘quasi-standard’ products, e.g. those like the Global Precipitation Measurement (GPM) mission [@houGlobalPrecipitationMeasurement2014] that have undergone substantial testing, perform better. Additionally, they report that products incorporating both in situ and satellite information (e.g. the Global Precipitation Climatology Project (GPCP) ) perform better than products based on a single data source.

Fewer studies comparing extreme precipitation events (e.g. events above the 90th percentile) exist. Many focus on climate model simulations [@sunyerIntercomparisonStatisticalDownscaling2015; @tryhornComparisonTechniquesDownscaling2011]  and trends [@janssenObservationalModelbasedTrends2014; @baoFutureIncreasesExtreme2017] while others focus on observations and satellites [@pendergrassUnevenNatureDaily2018; @aghakouchakEvaluationSatelliteretrievedExtreme2011; @lockhoffEvaluationSatelliteRetrievedExtreme2014]. @aghakouchakEvaluationSatelliteretrievedExtreme2011 compared extreme precipitation across four satellite platforms and found tradeoffs across products in terms of correct identification of precipitation above a threshold and measurements of the volume of extreme storms. While they showed that some datasets performed better than others in certain contexts, they ultimately concluded that no single precipitation product was ideal for detecting extremes because all of them failed to detect certain storms in certain regions. @lockhoffEvaluationSatelliteRetrievedExtreme2014 found that satellite retrieved extreme precipitation values generally matched station-based precipitation when using fuzzy metrics to evaluate agreement at larger spatiotemporal scales of ~330 km and 5 days. @pendergrassUnevenNatureDaily2018 showed that precipitation was less uneven in coarser versus finer-resolution satellite precipitation datasets, suggesting that coarser precipitation products may be unable to capture extreme precipitation to the same extent as higher resolution datasets. Other studies primarily evaluated extreme precipitation indicators like 90th percentile precipitation, extreme one-day precipitation and maximum number of consecutive wet days [@amitaiMultiplatformComparisonsRain2012; @manzanasPrecipitationVariabilityTrends2014]. These measures are meant to capture large storms that happen on at least an annual basis rather than specific to storms that trigger a natural disaster [@sunReviewGlobalPrecipitation2018; @manzanasPrecipitationVariabilityTrends2014]. 

 In a comparison of satellite and gauge precipitation data by specific to landslide sites in Italy, @rossiComparisonSatelliteRainfall2017 used intensity-duration thresholds as an aspect of the precipitation comparison. They found that data from Tropical Rainfall Measuring Mission (TRMM) satellite products [@kummerowTropicalRainfallMeasuring1998] tend to underestimate gauge data, particularly in mountainous areas where landslides are most likely to occur. They concluded that the satellite data are still useful for forecasting landslides  using intensity-duration thresholds as long as they are scaled appropriately to correct for local bias.

The intensity-duration threshold is a type of two-parameter statistical model used for landslide early warning systems, where rainstorms above the threshold curve are predicted to cause landslides [@scheevelPrecipitationThresholdsLandslide2017]. The curves are typically based on a power law (e.g. $I = a D^{-b}$) of storm intensity ($I$) as a function of duration ($D$) with fitted parameters $a$ and $b$. These power laws are valid in a particular region or climate and for a range of durations based on the training data [@guzzettiRainfallIntensityDuration2008]. Other statistical rainfall thresholds have been proposed, but generally rely upon either intensity or duration or both [@galantiComparisonStatisticalMethods2018; @leonarduzziPredictivePerformanceRainfall2017]. Here, we will investigate several power-law intensity-duration thresholds reviewed by @guzzettiRainfallIntensityDuration2008 as a basic way to compare precipitation measurements from different sources in the context of landslide hazard estimation. Furthermore, when precipitation is used to provide warning systems or guide recovery efforts from landslides, the timeliness, i.e. low latency, of the information matters [@kirschbaumAdvancesLandslideNowcasting2012], such that the issue of latency will also be considered in the investigation of intensity-duration thresholds.

 The goal of this analysis is to investigate the role of precipitation uncertainty preceding known historical landslide events, and to assess the implications for evaluating landslide hazards. Given the wide-ranging issues associated with precipitation estimation cited above, this study presents a multi-product, multi-site analysis focused on landslide-triggering storms. This work addresses an existing gap in evaluating extreme precipitation through the lens of natural hazards, while conducting inter-product analyses into storm characteristics of potential relevance for the hydrological community. This work furthers the analysis by @rossiComparisonSatelliteRainfall2017 by including ground-based radar and by rigorously analyzing each precipitation estimate preceding specific landslide events. Greater understanding of the areas of relative agreement and any divergence across products may provide guidance to practitioners and researchers choosing among precipitation products for studying landslides.

# Methods {#sec:methods}

We compared precipitation characteristics at known landslide sites using both the features of triggering storms and intensity-duration thresholds of landslide occurrence. Rainfall-triggered landslide sites were chosen from the NASA Global Landslide Catalog [NASA GLC; @kirschbaumGlobalLandslideCatalog2010] with a subset of landslide locations verified with ancillary satellite imagery (see @sec:site_selection). For each landslide location, precipitation was obtained from four different products (see @sec:precip_data) and the precipitation time series were split into individual storm events, with key characteristics of total depth, duration, intensity, peak intensity, and return period calculated (@sec:compute_storms). Finally, the storm events were plotted relative to landslide intensity-duration curves, with hit-ratios and false-alarm-ratios compared for each model-product combination (@sec:compute_idt_scores). 

## Study domain and landslide site selection {#sec:site_selection}

The NASA Global Landslide Catalog  [NASA GLC; @kirschbaumGlobalLandslideCatalog2010] was chosen as the source of landslide locations for this study, since it provides a large sample of landslide locations useful for evaluating heavy rainfall events.  The NASA GLC shares many strengths and weaknesses with other regional and global databases available [@kirschbaumGlobalLandslideCatalog2010; @mirusLandslidesUSAOccurrence2020]. Though the NASA GLC covers a broad spatial and temporal domain, it suffers from problems of precision and completeness. Landslide data are a comprised of a collection of second-hand observations made by organizations like the news media, governmental organizations like departments of transportation, along with available scientific reports. This means that landslides that are causing problems for people are reported more frequently, resulting in a substantial spatial bias towards populated areas. Landslide location accuracies range from ‘exact’ locations, to location uncertainties between 1km up to 50 km, depending on how specific the source article was about the location [@kirschbaumGlobalLandslideCatalog2010]. . Despite these limitations, the catalog was deemed fit for the purposes of this study, which is not to study a selection of landslides mechanisms and spatial distribution, but rather to compare precipitation products in the vicinity of hydrologically-triggered landslides where heavy rainfall events are likely to be present. Overall, the NASA GLC provided a substantial number of landslide locations (n=228) for this study that met the following selection criteria:

* Only landslide events reported as rainfall-driven, with a NASA GLC trigger category of "rain", "downpour", "continuous_rain", or "flooding" were included. Snow-related triggers were not included even though these are hydrologically related, because their precipitation is not contemporaneously linked with landslide triggers;
* Landslide events took place in the continental United States (CONUS) or Canada below $60^o$N  and after May 2015 ensuring data availability across each of the selected precipitation products; and
* The landslide location accuracy was reported to be 10 km or less. The value of 10 km was chosen since it is approximately equal to the spatial resolution of two of the precipitation products.

In total, 228 landslides were selected. Of those, the exact locations 80 were verified by a trained technician searching for a landslide scarp in visible satellite images of the terrain near the specified landslide location. The location specified by the NASA GLC was used for the remaining landslides where 31 were marked in the NASA GLC as "exact" locations, 51 as 1 km, 52 as 5 km, and 14 as 10 km accuracy. @Fig:site_map shows that many of the sites are located near the Pacific coast, likely due to the complex topography associated with landslides, as well as the population reporting bias of the catalog. The verified landslides are generally distributed evenly relative to the locations of the full selection of landslides.


![Map of all landslide sites considered in this analysis (n=228), colored by whether the location was approximate (n=148) or verified using aerial satellite imagery to identify a visible scarp (n=80); Source of landslide locations was the NASA GLC [@kirschbaumGlobalLandslideCatalog2010], source of the DEM data used for the basemap [@governmentofcanadaNorthAmericaElevation2007].](landslide_hydromet_paper.assets/site_map.png){#fig:site_map}

## Precipitation data sources {#sec:precip_data}

The gridded precipitation datasets in this study were chosen to be reflective of three common measurement methods: gauges, ground-based radar, and satellite. We were interested in products that are both freely available, having undergone extensive verification, and with coverage over at least the CONUS. An important additional criterion was that products be available at an hourly temporal resolution or finer in order to compute the characteristics of individual storm events. We further sought to include products with multiple latencies where available. The above criteria resulted in the precipitation products and features described in @tbl:products and summarized below.

### North American Land Data Assimilation System version 2 (NLDAS-2) meteorological dataset {.unnumbered}

The NLDAS-2 meteorological dataset [@xiaContinentalscaleWaterEnergy2012] is a combination of daily gauge-based National Center for Environmental Prediction (NCEP) Climate Prediction Center (CPC) precipitation with orographic corrections and hourly NCEP Doppler radar-based precipitation.  The gauge-based estimates are are disaggregated to hourly using the radar-based estimates, resulting in a near real-time hourly gridded product at $0.125^o$ (~$12$ km) resolution across North America going back to 1979 with a latency of approximately four days. Though it has coarser horizontal resolution relative to the other precipitation products used here, NLDAS-2 meteorological is a widely used gauge-based product that has been extensively validated over the recent period overlapping with this study [@livnehSpatiallyComprehensiveHydrometeorological2015; @longUncertaintyEvapotranspirationLand2014; @xiaBasinscaleAssessmentLand2016].

### Multi-Radar Multi-Sensor (MRMS) Quantitative Precipitation Estimate {.unnumbered}

MRMS precipitation estimates are primarily based on a centralized radar mosaic with 2-minute resolution over the US and Canada. This study uses an hourly version that also integrates data from numerical weather prediction, satellites, gauges, lightning sensors, and precipitation models [@zhangMultiRadarMultiSensorMRMS2015]. While both NLDAS-2 and MRMS estimates contain common information from gauges and radar, the NLDAS-2 product is primarily a gauge-based estimate while MRMS focuses on radar inputs. MRMS is the precipitation product with the shortest period of record among the products selected for this study, and so there are relatively few years of data for validation. However, it has by far the highest resolution at $.01^o$ (~1.1 km) and represents the state of the art in terms of leveraging computing resources to take advantage of a multitude of overlapping radar and other types of sensors.

### Integrated Multi-satellitE Retrievals for GPM (IMERG) {.unnumbered}

GPM IMERG precipitation estimates are a combination of multiple satellite measurements, including the GPM Core Observatory Microwave Imager which is considered the standard for other included satellites. In addition to active and passive microwave sensors, IMERG estimates include Infrared sensors, satellite-based radar, and precipitation gauge adjustments. The gauges are used for monthly bias correction [@huffmanIntegratedMultisatelliteRetrievals2020]. There are three IMERG products, Early, Late, and Final, of which we use the Early (~4 hour latency) and the Final (~3.5 month latency) in this study. The IMERG-Early product is available much more promptly than the IMERG-Final, but as a result some of the satellite retrievals are not incorporated because they have not yet arrived, and it cannot take advantage of some processing steps or monthly gauge correction  [@oEvaluationGPMIMERG2017]. IMERG-Final is recommended for research applications as being the most accurate, but would not be useful for predicting landslides in a timely fashion [@huffmanIntegratedMultisatelliteRetrievals2020]. Since IMERG products use the GPM active and passive microwave data as a standard with little-to-no information from gauges, they are fundamentally different from many other precipitation products available.

| Precipitation product                                        | Description                                                  | Spatial Resolution  | Temporal resolution | Typical Latency |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------- | ------------------- | --------------- |
| Integrated Multi-satellitE Retrievals for  Global precipitation measurement early run (IMERG-Early; @houGlobalPrecipitationMeasurement2014] | Global network of satellites unified by measurements from a single reference radar/radiometer satellite. | $0.1^o$ (~10 km)    | 30 minutes          | 4 hours         |
| Integrated Multi-satellitE Retrievals for  Global precipitation measurement (IMERG-Final; @houGlobalPrecipitationMeasurement2014] | In addition to the satellite data included in the IMERG early run, the final run includes late-arriving microwave overpasses, monthly gauge-based adjustments, and an algorithm that interpolates forward as well as backward in time. | $0.1^o$ (~10 km)    | 30 minutes          | 3.5 months      |
| Multi-Radar Multi-Sensor (MRMS; @zhangMultiRadarMultiSensorMRMS2015] | Integrates data from radars, satellites, precipitation gages, and other sensors to provide real-time decision support | $0.01^o$ (~1.1 km)  | 1 hour              | < 5 minutes     |
| North American Land Data Assimilation System version 2 (NLDAS-2) meteorological  [@xiaContinentalscaleWaterEnergy2012] | Disaggregation of Climate Prediction Center  daily precipitation using bias-corrected radar | $0.125^o$ (~ 12 km) | 1 hour              | 4 days          |

: The four precipitation products included in the comparison, representing gauge-, radar-, and satellite-based measurements {#tbl:products}

## Precipitation inter-comparison and computation of storm characteristics {#sec:compute_storms}

For each of the precipitation products, data were extracted for the precipitation grid enclosing the location of the landslide for the period between May 2015 (the earliest date MRMS data are available) and May 2020 (the latest release of IMERG-Final data at the time of this analysis). Following [@dinkuValidationHighResolution2008], a minimum threshold of 1 mm/hr was applied to the precipitation data to reduce noise. The data were then split into storm events, where a minimum inter-event time (MIT) criterion of 24 hours as described in @dunkerleyIdentifyingIndividualRain2008 was considered to mark the end of one storm and the beginning of the next. 

For each storm, the characteristics of total depth, duration, intensity, and peak intensity were computed and compared. The peak intensity for a storm was the intensity of the single maximum precipitation measurement of the storm. Depth and frequency were chosen since they reflect the most common metrics used in extreme hydrologic events [@englandjr.GuidelinesDeterminingFlood2019]. Intensity and duration were included because they are parameters commonly used to study rainfall-triggered landslides [@kirschbaumAdvancesLandslideNowcasting2012]. Previous studies have suggested that for certain landslides high peak intensity can contribute significantly to triggering a landslide independent of the overall storm depth, duration or intensity [@yuLandslidesRainfallCharacteristics2006; @corominasLandslideRainfallTriggers2002].  This idea is supported for example by observations that landslides are commonly initialized within hours of the peak intensity [@premchittLandslidesCausedRapid1986]. The precipitation rank and z-score among the four products for each landslide event were also computed for the day of the landslide as well as for the full May 2015-May 2020 precipitation record. Rank was chosen as in indicator of the relative magnitude of each product relative to the others, and the z-score is an indicator of the variability of each product relative to the others.

To facilitate comparison of storm characteristics within a single over-arching framework, the return period of the landslide-triggering storms was additionally computed using the NOAA precipitation atlas frequency estimations [@usdepartmentofcommerceNOAAAtlasPrecipitation2013]. The NOAA atlas provides return periods for discrete precipitation durations, namely 1, 2, 3, 6, 12, 24, 48, 72, 96, and 168 hours. In order to define a consistent return period for each storm, we used the maximum precipitation value for each applicable NOAA atlas duration rather than attempting to truncate the storm duration to one of the NOAA atlas durations which might have artificially lowered the return periods. For example, for the 3-hour duration, cumulative 3-hour precipitation totals were calculated for each time step of the storm, and the maximum value chosen. The return period for this maximum value was then retrieved from NOAA atlas. We then selected the maximum return period from among the 10 possible durations noted above for each landslide. For example, if the maximum 3-hour interval during the MIT-defined storm had a 25-year return period while the maximum 48-hour interval during the storm only had a 2-year return period, the return period of the 3-hour return period would be used in preference over the 48-hour return period or any other duration where the maximum return period was less than 25 years. This procedure ensured that we used the maximum applicable return period available from the NOAA atlas that occurred during each landslide-triggering storm. Values less than a 2-year return period are not included in the NOAA atlas, such that return period values were only assigned for a subset of landslide-triggering storms that exceeded that threshold. Frequency data were also unavailable for Canadian sites.

## Performance of intensity-duration thresholds using different precipitation products  {#sec:compute_idt_scores}

Intensity-Duration thresholds are a category of  simple models of landslide occurrence whereby a threshold is defined as a power law of the storm duration

$$
I=aD^{-b}
$$ {#eq:idt}
where *I* is intensity, *D* is duration, and *a* and *b* are fitted parameters to a particular dataset. Intensities above the threshold are used to predict the occurrence of a landslide [@segoniLandslidesTriggeredRainfall2014].  A range of thresholds have been calculated under different climates and over multiple scales, including globally  [@scheevelPrecipitationThresholdsLandslide2017; @caineRainfallIntensityDuration1980; @kirschbaumAdvancesLandslideNowcasting2012]. Three thresholds for this study [@caineRainfallIntensityDuration1980; @cannonWildfirerelatedDebrisFlow2005; @guzzettiRainfallThresholdsInitiation2007]  were obtained from a review by @guzzettiRainfallIntensityDuration2008 as a way to test the sensitivity of our results to a particular chosen threshold. Thresholds were only applied to applicable. Thresholds were used on applicable subsets of the data based on climate or other conditions. For example, since the @guzzettiRainfallThresholdsInitiation2007 was defined for“mild, marine west coast climates”, only data west of longitude 115W was included in that portion. The @cannonWildfirerelatedDebrisFlow2005 is intended for burned areas, and since the fire history of the locations in this study are unknown it is included only as a comparison point to the other thresholds. For each threshold-product combination, we computed a hit ratio (correctly predicted landslides over the total number of landslides) and a false alarm ratio (incorrectly predicted landslides over the total number of non-landslides)

# Results {#sec:results}

The four precipitation products examined in this study exhibit a great deal of variability in the time period leading up to the landslide event. As an example of the magnitudes and qualitative characteristics of that variability, @fig:cumulative shows the cumulative precipitation in the 30-days before a landslide at five sites.  The selected sites showcase multiple ways in which precipitation can differ among the products. For example, while the precipitation in panel (a) matches fairly closely for all products, while in panel (b) precipitation still appears to be correlated but also demonstrates a factor of six spread of precipitation values. In panel (c) the IMERG-Early product diverges substantially early on but ultimately the 30-day depth is nearly identical for all products. In panel (d) there is a broad spread of precipitation that nearly doubles suddenly during the landslide-triggering event to over 100 mm.  Panel (e) shows a likely landslide location error since none of the products register any precipitation close to the time of the event. We note that the differences in precipitation depths accumulated over these 30-day periods are of the same order of magnitude as the *annual* error in depth reported for products of the same category by @sunReviewGlobalPrecipitation2018. This may be because variability among products of different categories, e.g. satellite vs. radar, whereas the figure from @sunReviewGlobalPrecipitation2018 includes only satellite products. Alternatively, when aggregating over a whole year some of the variability among products cancels out, whereas landslide-triggering storms have a greater potential for error by virtue of being relatively brief events. 

![**Exposition into the types of precipitation differences leading up to landslide events:** Cumulative precipitation measurements at select landslide sites for the 30 days before the event. The precipitation is variable across the different products, and the selected sites each demonstrate diverse types of variability. Panel (a) shows a site where there were similar measurements among all products throughout the 30 days. In panel (b), all products are well correlated, but the accumulated depths greatly differ. In panel (c) shows the IMERG-Early product reports nearly 50mm less cumulative precipitation leading into the landslide-triggering storm, but then makes up the difference by detecting much more precipitation immediately before the landslide. In panel (d) there is a wide spread of approximately half the maximum total amount of precipitation. Finally, in panel (e) no landslide-triggering precipitation was detected by any product, suggesting a location error in the landslide record. ](landslide_hydromet_paper.assets/example_landslide_precipitation.png){#fig:cumulative}

The variability among products is also evident in the distribution of precipitation rank among products and z-score within products. The relative magnitude of the different precipitation products on the day of the landslide is shown in @Fig:bias_variability in terms of the rank among the four products for each day, and z-score among all non-zero data for a particular product. Both day-of-landslide precipitation and all other non-zero days in the study period are shown for comparison. The IMERG products appear to have identical ranks, which exceeds MRMS and is less than NLDAS-2 measurements. IMERG-Early has the highest z-scores among day-of-landslide precipitation, suggesting that the further interpolation in the IMERG-Final product reduces these outliers relative to IMERG-Early, although the median and third quartile values for IMERG-Final are the larger overall. For all products, there are larger z-scores in the entire record than the most extreme day-of-landslide precipitation, but the third quartile of the day-of-landslide precipitation is larger than that of the non-landslide-triggering precipitation.

![**Relative magnitude of precipitation products on the day of the landslide**: Rank among all products for the day, and z-score of precipitation as measured by each product for each of 228 events. The left panels show the entire precipitation record while the right panels show only the day-of-landslide precipitation for comparison.](landslide_hydromet_paper.assets/summary_statistic.png){#fig:bias_variability}

@Fig:scatter shows the characteristics of the landslide-triggering storms plotted against the ensemble mean of all the products for all the landslide sites and separately for the verified locations. There is reasonable agreement among products on the depth and duration of storms, with the exception of outliers below 10mm of total depth—corresponding with a fairly modest storm depth. Among the verified locations, there are fewer low-depth or duration values that are either outliers or near to the mean, suggesting that low measurements may reflect limitations in the GLC location accuracy for sites with only approximate locations.

The two satellite products have a pattern of distinctive readings relative to ground-based products in that they contain both the highest and lowest values of several storm characteristics. The IMERG products generally report higher peak hourly intensities, which is at least partially due to the shorter 30-minute time step. However, the higher peak intensities are more clearly reflected in longer return periods, which are based on hourly durations or longer for comparison with the NOAA Atlas. MRMS and NLDAS-2 have even lower return periods among the verified locations, suggesting that these products do not consistently detect high return period precipitation events. An examination of the relationship between return period and peak intensity showed a clear relationship, with the return period data reflecting a subset of the highest intensity storms due to the 2-year return period cutoff. The relationship between peak intensity and return period is not surprising given that the return period values were calculated by searching for the most intense period of each NOAA atlas duration.

There is good general agreement among products on the depth and duration of storms, with the exception of outliers below 10mm of total depth—corresponding with a fairly modest storm depth. Among the verified locations, there are fewer low-depth or duration values that are either outliers or near to the mean, suggesting that low measurements may reflect limitations in the GLC location accuracy for sites with only approximate locations.

![**Storm characteristics vs. the ensemble mean:** Depth, duration, intensity, peak intensity, and return period for each of the landslide-triggering storms as measured by four precipitation products. Least-squares regression lines with $95\%$ confidence intervals are also shown. Top panels show all 228 sites while the bottom panel only shows the 80 verified locations.](landslide_hydromet_paper.assets/scatter_ensemble_mean.png){#fig:scatter}

The precipitation products are examined in the context of landslide triggering thresholds in @Fig:intensity_duration, with the performance summarized in @tbl:threat . Interestingly, the choice of intensity-duration threshold does not appear to make a large difference namely the threshold curves are more similar than the variation in precipitation data across sites and among products. The MRMS or NLDAS-2 products tend to perform better than either IMERG product, with hit ratios between 0.63-0.88 and 0.66-0.76 rather than 0.59-0.70 and 0.53-0.68 among the verified landslide locations, respectively. All products perform comparably or better when using only the verified landslide locations relative to the approximate locations

 @Fig:intensity_duration shows a concentration of long-duration, low-intensity storms that are in the vicinity of 24 hour duration for all products. These storms may be an artifact of the MIT storm identification algorithm. Since the landslides did not have times specified, the entire day of the landslide was always included unless there was no rain all the way until the end of the day. This would have the  effect of computing lower total intensity values for storms that lasted only through the time of the landslide but did not persist thereafter. Many of the storms that did trigger landslides but were not correctly identified by the intensity-duration threshold fall into this group of approximately 24-hour low-intensity storms. Adjustments to storm delineation through a different algorithm or a higher minimum threshold may increase performance, especially for the IMERG products which showed the most low-intensity landslide triggering storms.

![Each storm in the precipitation record and established global or climactic intensity-duration thresholds. Landslide-triggering storms are shaded with darker blue. The top panel contains precipitation data for all sites while in the lower panel only verified sites are included. Points above each threshold are predicted by the threshold to be landslides, and so a larger proportion of landslides above the threshold indicates better performance.](landslide_hydromet_paper.assets/intensity_duration.png){#fig:intensity_duration}



| Product     | Include                       | **Hit ratio**                          |                  |                                    |      | **False alarm ratio**                  |                  |                                    |
| ----------- | ----------------------------- | -------------------------------------- | ---------------- | ---------------------------------- | ---- | -------------------------------------- | ---------------- | ---------------------------------- |
|             | Intensity-duration threshold: | @guzzettiRainfallIntensityDuration2008 | @clarizia1996sui | @cannonStormRainfallConditions2008 |      | @guzzettiRainfallIntensityDuration2008 | @clarizia1996sui | @cannonStormRainfallConditions2008 |
| IMERG-Early | All (n=176)                   | 0.65                                   | 0.55             | 0.47                               |      | 0.27                                   | 0.16             | 0.11                               |
|             | Verified (n=65)               | 0.68                                   | 0.59             | 0.53                               |      | 0.30                                   | 0.19             | 0.13                               |
| IMERG-Final | All (n=177)                   | 0.66                                   | 0.61             | 0.52                               |      | 0.31                                   | 0.20             | 0.14                               |
|             | Verified (n=64)               | 0.70                                   | 0.58             | 0.59                               |      | 0.34                                   | 0.25             | 0.16                               |
| NLDAS-2     | All (n=154)                   | 0.74                                   | 0.74             | 0.68                               |      | 0.22                                   | 0.24             | 0.18                               |
|             | Verified (n=59)               | 0.76                                   | 0.76             | 0.66                               |      | 0.22                                   | 0.22             | 0.18                               |
| MRMS        | All (n=156)                   | 0.83                                   | 0.58             | 0.56                               |      | 0.24                                   | 0.23             | 0.21                               |
|             | Verified (n=59)               | 0.88                                   | 0.76             | 0.63                               |      | 0.26                                   | 0.23             | 0.21                               |

Table: Hit ratio and false alarm ratio for each product and the @guzzettiRainfallIntensityDuration2008, @clarizia1996sui, and @cannonStormRainfallConditions2008 intensity-duration thresholds. {#tbl:threat}

# Discussion

Among the precipitation products chosen for this study, the two IMERG products identify both higher peak intensities and longer return periods relative to the other products. Interestingly, they also detect more anomalously low precipitation values. Low-intensity precipitation in all products was associated with long duration storm events (see @fig:intensity_duration)), which may occur because of “drizzle”, i.e. low-precipitation slightly above the 1 mm threshold that extended the MIT-computed duration of the storm and thereby reduced its overall intensity. As a result the IMERG products were particularly vulnerable to the identification of long-duration low-intensity storms as a result of the MIT method used in this study to separate storms. Those long-duration low-intensity storms had the effect of lowering the hit ratio. Because the IMERG products were able to identify higher intensity precipitation than the other products, it is possible that they would in fact perform better for identifying landslides if the low-intensity storm problem were mitigated.

All precipitation products performed reasonably well at identifying landslides using the published intensity-duration thresholds particularly considering that these thresholds were developed on different training data spanning large regions. However, they did not perform as well at excluding false alarms, most likely because of factors beyond intensity and duration that can influence landslide occurrence such as topography, soil type, recent wildfire or disturbance or land development. Some of the high-intensity precipitation that did not trigger any recorded landslides could be more reflective of adjacent areas that are not as susceptible to landslides. Conversely a landslide at a highly susceptible location, such as an area with high slopes that had recently been burned by wildfire could be triggered by less intense rain, potentially resulting as a miss on an intensity-duration curve. Even the 1.1 km resolution of the MRMS data could contain substantial variation in landslide susceptibility within an individual grid cell. The poorest performing products were the IMERG products despite their detecting more high-intensity events but because they also detected many low intensity events, causing the intensity-duration threshold to miss landslides.

MRMS and NLDAS-2 are relatively low latency products. In the case of IMERG-Early the short latency seemed to come at a cost of an exaggeration of the weaknesses and strengths of IMERG in identifying landslides. In particular, IMERG-Early had the greatest prevalence of low storm intensities, and so it ultimately performed the worst at landslide identification. Without changes to the precipitation processing, the low latency does indeed appear to be a liability in this case.

Precipitation measurements at verified landslide sites tended to be of higher magnitude than those at other sites with approximate locations for all products. Though this difference remains unexplained, one possibility is that some of the approximate landslide locations were too far away from the true landslide location for the precipitation measurements to be representative. Alternatively, there may have been other factors such as vegetation cover that made it more difficult to locate landslides on satellite imagery and also lowered the precipitation threshold that would trigger a landslide. The intensity-duration thresholds subsequently performed better at verified locations across all precipitation products. Since work on this study began, a compilation of U.S. landslides has been released by the USGS [@mirusLandslidesUSAOccurrence2020] which would also be a suitable source of landslide locations with perhaps greater location precision for future work along the same lines. 

# Conclusion

The precipitation products chosen for this study represent diverse measurement techniques that often recorded large differences in precipitation leading up to the landslide events evaluated here. As a result, each precipitation product differed in overall performance in predicting landslides using intensity-duration thresholds. Overall, the choice of intensity-duration threshold was not as consequential as the choice of precipitation product in identifying landslides. Performance from products that rely on ground-based sensors showed a more consistent landslide signal despite generally recording lower peak intensities and return periods.

Though it was hypothesized that peak intensity would be an important factor in identifying landslides, the results suggest instead that removal of noise on the low end, i.e. drizzle, may be more important. A particular challenge was the presence of low-intensity, long-duration storms preceding landslide events, most prevalent in the IMERG products. A more expansive evaluation of processing techniques for separating storms may potentially mitigate these issue, although each technique will produce artifacts in the comparisons.

Another limitation to the study landslide-triggering storms is the general lack of both exact landslide locations and specific time of day of the landslide events. The location limitation was reflected in better performance for verified landslide locations as compared to approximate locations, which implies that some of the approximate locations were incorrect to such an extent that the precipitation measurements were misaligned. This problem could be addressed by more extensive manual searches such as the one used in this study that identified the 80 verified landslide locations, or perhaps in the future by machine learning methods.

Using the methods tested in this study, those practitioners attempting to use intensity-duration thresholds as operation landslide models would do well to select a product like MRMS that has extremely low latency and performs well at identifying landslides. None of the products were particularly good at filtering out false alarms of landslides. However, a model that takes into account landslide susceptibility has the potential to reduce false alarms. Therefore, an additional recommendation would be for practitioners to consider more than one precipitation product, i.e. multiple precipitation estimates simultaneously, as a way to confirm stronger precipitation signals and to minimize the influence of noise.

# Bibliography